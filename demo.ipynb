{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataloaders\n",
    "from model.hopfield.network import DeepHopfieldEnergy\n",
    "from model.function.network import Network\n",
    "from model.function.cost import SquaredError\n",
    "from model.hopfield.minimizer import FixedPointMinimizer\n",
    "from training.sgd import EquilibriumProp, Backprop, AugmentedFunction\n",
    "from training.epoch import Trainer, Evaluator\n",
    "from training.monitor import Monitor, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'dhn-2h'\n",
    "\n",
    "batch_size = 16\n",
    "layer_shapes = [(1, 28, 28), (1024,), (1024,), (10,)]\n",
    "weight_gains = [0.7, 0.7, 0.7]\n",
    "num_iterations_inference = 50\n",
    "num_iterations_training = 20\n",
    "nudging = 0.2\n",
    "learning_rates_weights = [0.2, 0.05, 0.01]\n",
    "learning_rates_biases = [0.2, 0.05, 0.01]\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'MNIST'\n",
    "training_loader, test_loader = load_dataloaders(dataset, batch_size, augment_32x32=False, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the network (DHN: deep Hopfield network)\n",
    "energy_fn = DeepHopfieldEnergy(layer_shapes, weight_gains)\n",
    "\n",
    "# Set the device on which we run and train the network\n",
    "if torch.cuda.is_available(): device = \"cuda\"\n",
    "else: device = \"cpu\"\n",
    "energy_fn.set_device(device)\n",
    "\n",
    "# Define the cost function (mean squared error)\n",
    "output_layer = energy_fn.layers()[-1]\n",
    "cost_fn = SquaredError(output_layer)\n",
    "\n",
    "network = Network(energy_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the energy minimizer and gradient estimator (equilibrium propagation)\n",
    "params = energy_fn.params()\n",
    "layers = energy_fn.layers()\n",
    "free_layers = network.free_layers()\n",
    "\n",
    "augmented_fn = AugmentedFunction(energy_fn, cost_fn)\n",
    "energy_minimizer_training = FixedPointMinimizer(augmented_fn, free_layers)\n",
    "estimator = EquilibriumProp(params, layers, augmented_fn, cost_fn, energy_minimizer_training)\n",
    "estimator.nudging = nudging\n",
    "estimator.variant = 'centered'\n",
    "\n",
    "energy_minimizer_training.num_iterations = num_iterations_training\n",
    "energy_minimizer_training.mode = 'asynchronous'\n",
    "\n",
    "# Build the optimizer (SGD)\n",
    "learning_rates = learning_rates_biases + learning_rates_weights\n",
    "momentum = 0.\n",
    "weight_decay = 0. * 1e-4\n",
    "optimizer = Optimizer(energy_fn, cost_fn, learning_rates, momentum, weight_decay)\n",
    "\n",
    "# Define the trainer (to perform one epoch of training) and the evaluator (to evaluate the model on the test set)\n",
    "energy_minimizer_inference = FixedPointMinimizer(energy_fn, free_layers)\n",
    "energy_minimizer_inference.num_iterations = num_iterations_inference\n",
    "energy_minimizer_inference.mode = 'asynchronous'\n",
    "\n",
    "\n",
    "trainer = Trainer(network, cost_fn, params, training_loader, estimator, optimizer, energy_minimizer_inference)\n",
    "\n",
    "\n",
    "# The evaluator is responsible for network inference\n",
    "evaluator = Evaluator(network, cost_fn, test_loader, energy_minimizer_inference)\n",
    "\n",
    "# Define the scheduler for the learning rates\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "\n",
    "# Define the path and the monitor to perform the run\n",
    "path = '/'.join(['papers/fast-drn', model, 'EP'])\n",
    "monitor = Monitor(energy_fn, cost_fn, trainer, scheduler, evaluator, path)\n",
    "\n",
    "# Print the characteristics of the run\n",
    "print('Dataset: {} -- batch_size={}'.format(dataset, batch_size))\n",
    "print('Network: ', energy_fn)\n",
    "print('Cost function: ', cost_fn)\n",
    "print('Energy minimizer during inference: ', energy_minimizer_inference)\n",
    "print('Energy minimizer during training: ', energy_minimizer_training)\n",
    "print('Gradient estimator: ', estimator)\n",
    "print('Parameter optimizer: ', optimizer)\n",
    "print('Number of epochs = {}'.format(num_epochs))\n",
    "print('Path = {}'.format(path))\n",
    "print('Device = {}'.format(device))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the Experiment\n",
    "monitor.run(num_epochs, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
